{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제1\n",
    "### 데이터 정규화를 위한 Mean과 Std 값 찾기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import 단\n",
    "    - BASE_PATH : link_dl 위치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kroad/jcw/link_dl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "BASE_PATH = str(Path(os.getcwd()).resolve().parent.parent)  # BASE_PATH: /.../link_dl\n",
    "print(BASE_PATH)\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._99_common_utils.utils import get_num_cpu_cores, is_linux, is_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean과 std 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(data_loader):\n",
    "    mean_sum = 0.0\n",
    "    squared_mean_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, _ in data_loader:\n",
    "        batch_samples = images.size(0)  # 배치 크기\n",
    "        total_samples += batch_samples\n",
    "\n",
    "        # (B, C, H, W) 형태에서 (B, C, H*W)로 펼치기\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "\n",
    "        # 각 배치별 평균과 제곱평균을 누적\n",
    "        mean_sum += images.mean([0, 2]) * batch_samples\n",
    "        squared_mean_sum += (images**2).mean([0, 2]) * batch_samples\n",
    "\n",
    "    # 전체 평균 및 표준편차 계산\n",
    "    mean = mean_sum / total_samples\n",
    "    std = (squared_mean_sum / total_samples - mean**2).sqrt()\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"mean:\", mean)\n",
    "    print(\"std:\", std)\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습용 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores() if is_linux() or is_windows() else 0\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    print(\"학습용 데이터셋의 평균 및 표준편차\")\n",
    "    cal_mean , cal_std = calculate_mean_std(train_data_loader)\n",
    "\n",
    "    #정규화 함수\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=cal_mean, std=cal_std),\n",
    "    )\n",
    "\n",
    "    # # 이미지 크기 조정을 위한 transform 수정 -- resnet gray_scale 변환\n",
    "    # mnist_transforms = nn.Sequential(\n",
    "    #     transforms.Resize(224),  # ResNet 입력 크기\n",
    "    #     transforms.ConvertImageDtype(torch.float),\n",
    "    #     transforms.Normalize(mean=[0.485], std=[0.229])  # 단일 채널용 정규화\n",
    "    # )\n",
    "\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트용 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    print(\"테스트용 데이터셋의 평균 및 표준편차\")\n",
    "    cal_mean , cal_std = calculate_mean_std(test_data_loader)\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=cal_mean, std=cal_std),\n",
    "    )\n",
    "\n",
    "    # # 이미지 크기 조정을 위한 transform 수정 -- resnet gray_scale 변환\n",
    "    # mnist_transforms = nn.Sequential(\n",
    "    #     transforms.Resize(224),  # ResNet 입력 크기\n",
    "    #     transforms.ConvertImageDtype(torch.float),\n",
    "    #     transforms.Normalize(mean=[0.485], std=[0.229])  # 단일 채널용 정규화\n",
    "    # )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 메인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "Number of Data Loading Workers: 12\n",
      "학습용 데이터셋의 평균 및 표준편차\n",
      "\n",
      "\n",
      "mean: tensor([0.2856])\n",
      "std: tensor([0.3529])\n",
      "\n",
      "Num Test Samples:  10000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "테스트용 데이터셋의 평균 및 표준편차\n",
      "\n",
      "\n",
      "mean: tensor([0.2868])\n",
      "std: tensor([0.3524])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = {'batch_size': 2048, }\n",
    "    wandb.init(mode=\"disabled\", config=config)\n",
    "\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms = get_fashion_mnist_data()\n",
    "    print()\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 학습 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cnn 모델 불러오기\n",
    "    - code의 _10_cnn_architectures 가져옴\n",
    "        - 입력값 : 배치 크기, 입력 채널 수(1- 흑백), 이미지 크기 : 28 x 28 (입력값 고정)\n",
    "\n",
    "        - 출력값 : n_output (classify 하려는 클래스의 갯수와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kroad/jcw/link_dl\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "BASE_PATH = str(Path(os.getcwd()).resolve().parent.parent)  # BASE_PATH: /.../link_dl\n",
    "print(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = str(Path(os.getcwd()).resolve())\n",
    "\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "  os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._08_fcn_best_practice.c_trainer import ClassificationTrainer\n",
    "from _01_code._08_fcn_best_practice.e_arg_parser import get_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제공된 cnn 모델로 94% 달성 실패\n",
    "    - 'epochs': 1000,\n",
    "    - 'batch_size': 32,\n",
    "    - 'validation_intervals': 10,\n",
    "    - 'learning_rate': 0.001,\n",
    "    - 'early_stop_patience': 20,\n",
    "    - 'early_stop_delta': 0.0001\n",
    "\n",
    "-- 최저 loss : 0.25023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "  class MyModel(nn.Module):\n",
    "    def __init__(self, in_channels, n_output):\n",
    "      super().__init__()\n",
    "\n",
    "      self.model = nn.Sequential(\n",
    "        # B x 1 x 28 x 28 --> B x 6 x (28 - 5 + 1) x (28 - 5 + 1) = B x 6 x 24 x 24 \n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 6 x 24 x 24 --> B x 6 x 12 x 12\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        # B x 6 x 12 x 12 --> B x 16 x (12 - 5 + 1) x (12 - 5 + 1) = B x 16 x 8 x 8\n",
    "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 16 x 8 x 8 --> B x 16 x 4 x 4\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        # B x 16 x 4 x 4 --> B x 256\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, n_output), # output - classify 하려는 클래스의 갯수와 동일\n",
    "      )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.model(x)\n",
    "      return x\n",
    "\n",
    "  # 1 * 28 * 28\n",
    "  my_model = MyModel(in_channels=1, n_output=10)\n",
    "\n",
    "  return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ResNet 적용 (실패)\n",
    "    - 첫 레이어 수정 (3채널 -> 1채널)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import models\n",
    "\n",
    "# def get_resnet(n_output=10, pretrained=True):\n",
    "#     base_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "    \n",
    "#     # 입력 채널 수정 (1채널)\n",
    "#     base_model.conv1 = nn.Conv2d(\n",
    "#         in_channels=1,\n",
    "#         out_channels=64,\n",
    "#         kernel_size=(7, 7),\n",
    "#         stride=(2, 2),\n",
    "#         padding=(3, 3),\n",
    "#         bias=False\n",
    "#     )\n",
    "\n",
    "#     num_ftrs = base_model.fc.in_features\n",
    "#     base_model.fc = nn.Linear(num_ftrs, 10)\n",
    "    \n",
    "#     return base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cnn train 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:v2sk2wcj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 8.3%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-11-23_23-19-52</strong> at: <a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist/runs/v2sk2wcj' target=\"_blank\">https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist/runs/v2sk2wcj</a><br/> View project at: <a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist' target=\"_blank\">https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241123_231953-v2sk2wcj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:v2sk2wcj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kroad/jcw/link_dl/_02_homeworks/homework_3/wandb/run-20241123_232324-jcrogk4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist/runs/jcrogk4d' target=\"_blank\">[resnet]2024-11-23_23-23-24</a></strong> to <a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist' target=\"_blank\">https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist/runs/jcrogk4d' target=\"_blank\">https://wandb.ai/jcw202017-korea-university-of-technology-and-education/cnn_mnist/runs/jcrogk4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'epochs': 1000, 'batch_size': 32, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 20, 'early_stop_delta': 0.0001}\n",
      "Training on device cpu.\n",
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "Number of Data Loading Workers: 12\n",
      "학습용 데이터셋의 평균 및 표준편차\n",
      "\n",
      "\n",
      "mean: tensor([0.2860])\n",
      "std: tensor([0.3530])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_resnet_with_progress' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m   wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m   \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m train_data_loader, validation_data_loader, mnist_transforms \u001b[38;5;241m=\u001b[39m get_fashion_mnist_data()\n\u001b[0;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_resnet_with_progress\u001b[49m(n_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwatch(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_resnet_with_progress' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 32,\n",
    "    'validation_intervals': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stop_patience': 20,\n",
    "    'early_stop_delta': 0.0001\n",
    "  }\n",
    "\n",
    "  project_name = \"cnn_mnist\"\n",
    "  wandb.init(\n",
    "    # mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=project_name,\n",
    "    notes=\"mnist experiment with cnn\",\n",
    "    tags=[\"cnn\", \"mnist\"],\n",
    "    name=\"[resnet]\"+run_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print()\n",
    "  print(wandb.config)\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Training on device {device}.\")\n",
    "\n",
    "  train_data_loader, validation_data_loader, mnist_transforms = get_fashion_mnist_data()\n",
    "  model = get_cnn_model(n_output=10, pretrained=True)\n",
    "  model.to(device)\n",
    "  wandb.watch(model)\n",
    "\n",
    "  from torchinfo import summary\n",
    "  summary(model=model, input_size=(1, 1, 28, 28))\n",
    "\n",
    "  optimizer = optim.SGD(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  classification_trainer = ClassificationTrainer(\n",
    "    project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n",
    "    run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "  )\n",
    "  classification_trainer.train_loop()\n",
    "\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 Accuracy 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_PATH = str(Path(__file__).resolve().parent.parent.parent)  # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._08_fcn_best_practice.d_tester import ClassificationTester\n",
    "\n",
    "\n",
    "def main():\n",
    "  mnist_test_images, test_data_loader, mnist_transforms = get_fashion_mnist_test_data()\n",
    "\n",
    "  test_model = get_cnn_model()\n",
    "  classification_tester = ClassificationTester(\n",
    "    \"mnist\", test_model, test_data_loader, mnist_transforms, CHECKPOINT_FILE_PATH\n",
    "  )\n",
    "  classification_tester.test()\n",
    "\n",
    "  print()\n",
    "\n",
    "  img, label = mnist_test_images[0]\n",
    "  print(\"     LABEL:\", label)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "\n",
    "  # torch.tensor(np.array(mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0).shape: (1, 1, 28, 28)\n",
    "  output = classification_tester.test_single(\n",
    "    torch.tensor(np.array(mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "  )\n",
    "  print(\"PREDICTION:\", output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 예측 결과 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
